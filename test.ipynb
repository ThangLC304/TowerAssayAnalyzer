{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rearranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from pathlib import Path\n",
    "from functools import partial, wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "# Open dialog to choose the .txt file\n",
    "file_type = [('Text File', '*.txt')]\n",
    "default_dir = 'Input'\n",
    "file_path = filedialog.askopenfilename(filetypes=file_type, initialdir=default_dir)\n",
    "\n",
    "# Read the .txt file into a dataframe\n",
    "raw_df = pd.read_csv(file_path, sep = \"\\t\")\n",
    "\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "for col in raw_df.columns:\n",
    "    if \"unnamed\" in col.lower() or \"prob\" in col.lower():\n",
    "        raw_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first frame of the video to get a sample image\n",
    "\n",
    "# Open dialog to choose the .mp4 file\n",
    "file_type = [('Video File', '*.mp4')]\n",
    "default_dir = 'Input'\n",
    "file_path = filedialog.askopenfilename(filetypes=file_type, initialdir=default_dir)\n",
    "video_P = Path(file_path)\n",
    "\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "_, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "# Export frame as a .png file\n",
    "image_P = video_P.parent / (video_P.stem + \".png\")\n",
    "cv2.imwrite(str(image_P), frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tanks(im):\n",
    "    example_tanks = {}\n",
    "\n",
    "    tank_names = ['Top Left', 'Top Right', 'Bottom Left']\n",
    "\n",
    "    def tank_selector(im, tank_name):\n",
    "        while True:\n",
    "            selected_pixel = cv2.selectROI('Selecting tank at position'+str(tank_name), im)\n",
    "            \n",
    "            # print out the coordinates of top left and bottom right pixel of the ROI\n",
    "            print('Tank at position: ', tank_name)\n",
    "            print('Top left pixel: x = {}, y = {}'.format(selected_pixel[0], selected_pixel[1]))\n",
    "            print('Bottom right pixel: x = {}, y = {}'.format(selected_pixel[0] + selected_pixel[2], selected_pixel[1] + selected_pixel[3]))\n",
    "            print('Middle line: y = {}'.format(selected_pixel[1] + selected_pixel[3] / 2))\n",
    "            tank_d = math.ceil((selected_pixel[2] + selected_pixel[3]) / 2)\n",
    "            print('Diameter of the tank : ', tank_d)\n",
    "            print()\n",
    "            example_tanks[tank_name] = selected_pixel\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    for name in tank_names:\n",
    "        tank_selector(im, name)\n",
    "\n",
    "    return example_tanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_P = Path(r\"C:\\Code\\ChungyuanProjects\\TowerAssayAnalyzer\\Input\\Zebrafish Tower\\A - Novel Tank Test\\01 - Control (1st Batch).png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im = cv2.imread(str(image_P))\n",
    "example_wells = get_tanks(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanks_col = 5\n",
    "tanks_row = 2\n",
    "\n",
    "# tanks number\n",
    "# 10 9 8 7 6\n",
    "# 5 4 3 2 1\n",
    "\n",
    "tanks_dict = {}\n",
    "\n",
    "TL_num = tanks_col * tanks_row\n",
    "TR_num = TL_num - tanks_col + 1\n",
    "BL_num = tanks_col\n",
    "\n",
    "tanks_dict[TL_num] = example_wells['Top Left']\n",
    "tanks_dict[TR_num] = example_wells['Top Right']\n",
    "tanks_dict[BL_num] = example_wells['Bottom Left']\n",
    "tanks_dict[1] = (tanks_dict[6][0] - (tanks_dict[10][0] - tanks_dict[5][0]), tanks_dict[6][1] - (tanks_dict[10][1] - tanks_dict[5][1]), tanks_dict[6][2]*(tanks_dict[5][2]/tanks_dict[10][2]), tanks_dict[6][3]*(tanks_dict[5][3]/tanks_dict[10][3]))\n",
    "\n",
    "def fill_row(tanks_dict, start, end, display = True):\n",
    "    x_sep = (tanks_dict[start][0] - tanks_dict[end][0])/(end - start)\n",
    "    y_sep = (tanks_dict[start][1] - tanks_dict[end][1])/(end - start)\n",
    "    w_sep = (tanks_dict[start][2] - tanks_dict[end][2])/(end - start)\n",
    "    h_sep = (tanks_dict[start][3] - tanks_dict[end][3])/(end - start)\n",
    "\n",
    "    for i in range(start+1, end):\n",
    "        tanks_dict[i] = (tanks_dict[end][0] + x_sep*(end-i), tanks_dict[end][1] + y_sep*(end-i), tanks_dict[end][2] + w_sep*(end-i), tanks_dict[end][3] + h_sep*(end-i))\n",
    "    \n",
    "    if display:\n",
    "        for key, value in locals().items():\n",
    "            print(key + ' = ' + str(value))\n",
    "\n",
    "    return tanks_dict\n",
    "\n",
    "for row in range(0, tanks_row):\n",
    "    tanks_dict = fill_row(tanks_dict, 1 + row*tanks_col, (row+1)*tanks_col)\n",
    "    # row = 0, fill(tanks_dict, 1 + 0*5,  (0+1)*5)\n",
    "    # row = 1, fill(tanks_dict, 1 + 1*5,  (1+1)*5)\n",
    "\n",
    "# tanks_dict = fill_row(tanks_dict, 1, 5)\n",
    "# tanks_dict = fill_row(tanks_dict, 6, 10)\n",
    "\n",
    "# round up all the values in tanks_dict to integers\n",
    "for key in tanks_dict:\n",
    "    tanks_dict[key] = tuple([int(round(i)) for i in tanks_dict[key]])\n",
    "\n",
    "tanks_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(str(image_P))\n",
    "\n",
    "# Display predicted tanks\n",
    "def display_tanks():\n",
    "    for i in range(1, 11):\n",
    "        x, y, w, h = tanks_dict[i]\n",
    "        cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(im, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Tanks', im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "display_tanks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from Libs.misc import display_coords\n",
    "\n",
    "def coord_generator(box, points = 1000):\n",
    "    x, y, w, h = box\n",
    "    coords = []\n",
    "    for i in range(points):\n",
    "        x_coord = random.randint(x, x+w)\n",
    "        y_coord = random.randint(y, y+h)\n",
    "        coords.append((x_coord, y_coord))\n",
    "    return coords\n",
    "\n",
    "def mix_up(input_dict, mix_ratio = 0.3):\n",
    "    # input_dict has 10 keys \n",
    "    # keys are 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "    # values are coordinates inside the tanks\n",
    "    # mix_ratio is the ratio of mixing up the coordinates\n",
    "    # mix_ratio = 0.3 means 30% of the coordinates will be mixed up\n",
    "\n",
    "    for i in range(1, len(input_dict)+1):\n",
    "        if i == 1:\n",
    "            continue\n",
    "        else:\n",
    "            for j in range(1, len(input_dict[i])+1):\n",
    "                if random.random() < mix_ratio:\n",
    "                    # swap the coordinates\n",
    "                    input_dict[i][j-1], input_dict[i-1][j-1] = input_dict[i-1][j-1], input_dict[i][j-1]\n",
    "    return input_dict\n",
    "                    \n",
    "def mix_up_df(input_df, mix_ratio = 0.3):\n",
    "\n",
    "    for i in range(1, len(input_df.columns)+1, 2):\n",
    "        if i == 1:\n",
    "            continue\n",
    "        else:\n",
    "            for j in range(1, len(input_df)+1):\n",
    "                if random.random() < mix_ratio:\n",
    "                    # swap the coordinates\n",
    "                    input_df.iloc[j-1, i-1], input_df.iloc[j-1, i-2] = input_df.iloc[j-1, i-2], input_df.iloc[j-1, i-1]\n",
    "\n",
    "    return input_df\n",
    "\n",
    "test_dict = {}\n",
    "for i in range(1, 11):\n",
    "    test_dict[i] = coord_generator(tanks_dict[i])\n",
    "\n",
    "\n",
    "columns = []\n",
    "for i in range (1, 11):\n",
    "    columns.append('x' + str(i))\n",
    "    columns.append('y' + str(i))\n",
    "\n",
    "test_df = pd.DataFrame(columns = columns)\n",
    "for i in range(1, 11):\n",
    "    test_df['x' + str(i)] = [x for x, y in test_dict[i]]\n",
    "    test_df['y' + str(i)] = [y for x, y in test_dict[i]]\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_coords(test_df, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_dict = mix_up(test_dict, mix_ratio = 0.3)\n",
    "mixed_dict\n",
    "\n",
    "# turn test_dict into dataframe, with 20 columns\n",
    "# columns = ['x1', 'y1', 'x2', 'y2', ..., 'x10', 'y10']\n",
    "# rows = 1000\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "mixed_df = pd.DataFrame(columns = columns)\n",
    "for i in range(1, 11):\n",
    "    mixed_df['x' + str(i)] = [x for x, y in mixed_dict[i]]\n",
    "    mixed_df['y' + str(i)] = [y for x, y in mixed_dict[i]]\n",
    "\n",
    "mixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_coords(mixed_df, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Tanks', im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_box(input_x, input_y, box):\n",
    "    x, y, w, h = box\n",
    "    return x <= input_x <= x + w and y <= input_y <= y + h\n",
    "    \n",
    "def in_which_tank(x, y):\n",
    "    for tank_num, tank_box in tanks_dict.items():\n",
    "        if in_box(x, y, tank_box):\n",
    "            return tank_num\n",
    "    return -1\n",
    "\n",
    "true_df = pd.DataFrame(columns=test_df.columns)\n",
    "for idx, row in test_df.iterrows():\n",
    "    for j in range(1, 11):\n",
    "        x = row['x' + str(j)]\n",
    "        y = row['y' + str(j)]\n",
    "        \n",
    "        tank = in_which_tank(x, y)\n",
    "\n",
    "        if tank != -1:\n",
    "            true_df.loc[idx, 'x' + str(j)] = x\n",
    "            true_df.loc[idx, 'y' + str(j)] = y     \n",
    "\n",
    "true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_coords(true_df, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.misc import load_threshold\n",
    "\n",
    "threshold_path = 'Bin/thresholds.json'\n",
    "\n",
    "speed1, speed2 = load_threshold(threshold_path, 'SPEED_1', 'SPEED_2')\n",
    "\n",
    "speed1, speed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.misc import get_file_path, load_raw_df, clean_df\n",
    "\n",
    "file_type = [('Text File', '*.txt')]\n",
    "default_dir = 'Input'\n",
    "txt_path = get_file_path(file_type, default_dir)\n",
    "\n",
    "raw_df, tanks_list = load_raw_df(txt_path)\n",
    "\n",
    "raw_df, _ = clean_df(raw_df, fill = True)\n",
    "\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to a csv file\n",
    "raw_df.to_csv('Output/raw_df_withgap.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.misc import display_coords, get_image\n",
    "\n",
    "im, _ = get_image(source = 'image')\n",
    "display_coords(raw_df, im, window_name = \"Fish 3\", tanks_list = tanks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.analyzer import NovelTankTest\n",
    "\n",
    "nvtt1 = NovelTankTest(raw_df)\n",
    "\n",
    "summary_dict = nvtt1.basiccal()\n",
    "\n",
    "summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(15.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.misc import *\n",
    "\n",
    "final_df, im, tanks_list = draw_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_trajectories(final_df, im, tanks_list, until = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.misc import *\n",
    "\n",
    "final_df_1, im_1, tanks_list_1 = draw_prep(mode = 'single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "time_range = [200, 250]\n",
    "\n",
    "time = time_range[0]\n",
    "while True:\n",
    "    print('Time frame: ', time)\n",
    "    draw_trajectories(final_df_1, im_1, tanks_list_1, until = time, wait = 5)\n",
    "    time += 1\n",
    "    cv2.waitKey(1)\n",
    "    # If \"spacebar\" is pressed, pause the video\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        cv2.waitKey(0)\n",
    "    if time == time_range[1] or cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "for time in range(200, 250):\n",
    "    draw_trajectories(final_df_1, im_1, tanks_list_1, until = time, wait = 5)\n",
    "    # if a key is pressed, pause the video\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# draw_trajectories(final_df_1, im_1, tanks_list_1, until = 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create an example dataframe with column X Y\n",
    "# in X there are some Nan values, along with int values\n",
    "# in Y there are some Nan values, along with int values\n",
    "\n",
    "df = pd.DataFrame({'X': [1, 2, 3, np.nan, 5, np.nan, 7, 8, 9, 10],\n",
    "                     'Y': [1, 2, 3, 4, 5, 6, 7, 8, 9, np.nan]})\n",
    "\n",
    "# find nan in X\n",
    "nan_coords = np.where(df['X'].isnull())[0]\n",
    "len(nan_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = [1, 2, 3, 4, 7, 8, 9, 15, 16, 17]\n",
    "\n",
    "# turn it into numpy array\n",
    "my_array = np.array(my_array)\n",
    "\n",
    "# split my_array into groups of continous numbers, sep = 1\n",
    "# output = [[1, 2, 3, 4], [7, 8, 9], [15, 16, 17]]\n",
    "\n",
    "def split_array(my_array, sep = 1):\n",
    "    # get the difference between each number\n",
    "    diff = np.diff(my_array)\n",
    "    # get the index of the difference that is larger than sep\n",
    "    split_index = np.where(diff > sep)[0]\n",
    "    # split the array into groups\n",
    "    split_array = np.split(my_array, split_index + 1)\n",
    "    return split_array\n",
    "\n",
    "split_array(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# test cuda\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.analyzer import *\n",
    "import pandas as pd\n",
    "\n",
    "total_csv_path = r'D:\\Code\\TowerAssayAnalyzer\\Output\\arranged_C - Mirror Biting Test - full.csv'\n",
    "\n",
    "total_df = pd.read_csv(total_csv_path)\n",
    "\n",
    "# get the first tank\n",
    "first_tank_df = total_df[['X1', 'Y1']].copy()\n",
    "\n",
    "NTT_Tank1 = NovelTankTest(first_tank_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTT_Tank1.distance.variables(magic = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the noveltanktest class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.misc import load_raw_df, clean_df\n",
    "from Libs.executor import *\n",
    "\n",
    "txt_path = \"Input/Zebrafish Tower/A - Novel Tank Test/trajectories.txt\"\n",
    "df, _ = load_raw_df(txt_path)\n",
    "df, _ = clean_df(df, fill = True)\n",
    "\n",
    "display_dict = NovelTank_Display(df).rows\n",
    "\n",
    "for key, value in display_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the shoalingtest class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.misc import load_raw_df, clean_df\n",
    "from Libs.executor import *\n",
    "\n",
    "txt_path = \"Input/Zebrafish Tower/A - Novel Tank Test/trajectories.txt\"\n",
    "whole_df, _ = load_raw_df(txt_path)\n",
    "whole_df, _ = clean_df(whole_df, fill=True)\n",
    "df1, df2, df3 = whole_df.iloc[:, :2], whole_df.iloc[:, 2:4], whole_df.iloc[:, 4:]\n",
    "\n",
    "whole_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.open('Bin/landing_photo.png')\n",
    "\n",
    "# crop 200px around the image\n",
    "crop_px = 400\n",
    "hor_move = 75\n",
    "ver_move = -35\n",
    "im = im.crop((crop_px+hor_move, crop_px+ver_move, im.width - crop_px+hor_move, im.height - crop_px+ver_move))\n",
    "\n",
    "# save\n",
    "im.save('Bin/landing_photo_cropped.png')\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTO ANALYZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTS data structure loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from Libs.batchprocess import MY_DIR\n",
    "\n",
    "\n",
    "tests = ['Novel Tank', 'Shoaling', 'Mirror Biting', 'Social Interaction', 'Predator Avoidance']\n",
    "checks = ['novel', 'shoal', 'mirror', 'social', 'predator']\n",
    "PROJECT_DIR = r'D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT'\n",
    "PROJECT_DIR = Path(PROJECT_DIR)\n",
    "\n",
    "# Get all immediate subdirectories of PROJECT_DIR\n",
    "subdirectories = [x for x in PROJECT_DIR.glob(\"*/\") if x.is_dir()]\n",
    "TESTS = {}\n",
    "for subdirectory in subdirectories:\n",
    "    if checks[0] in subdirectory.name.lower():\n",
    "        TESTS[1] = MY_DIR(name=tests[0], dir_path=subdirectory)\n",
    "    elif checks[1] in subdirectory.name.lower():\n",
    "        TESTS[2] = MY_DIR(name=tests[1], dir_path=subdirectory, no_gap = True)\n",
    "    elif checks[2] in subdirectory.name.lower():\n",
    "        TESTS[3] = MY_DIR(name=tests[2], dir_path=subdirectory)\n",
    "    elif checks[3] in subdirectory.name.lower():\n",
    "        TESTS[4] = MY_DIR(name=tests[3], dir_path=subdirectory)\n",
    "    elif checks[4] in subdirectory.name.lower():\n",
    "        TESTS[5] = MY_DIR(name=tests[4], dir_path=subdirectory)\n",
    "\n",
    "# CHECK POINT 1\n",
    "if len(TESTS) == 5:\n",
    "    print('TESTS data structure loaded successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Novel Tank Test, we have: \n",
      "Batch 1 : [WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/01 - Novel Tank Test/A - Control (1st Batch)'), WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/01 - Novel Tank Test/B - 0.1 ppm (1st Batch)'), WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/01 - Novel Tank Test/C - 10 ppm (1st Batch)')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "TESTS[test_num].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Batch 1, we have: \n",
      "Condition A : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch) \n",
      "Condition B : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\B - 0.1 ppm (1st Batch) \n",
      "Condition C : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\C - 10 ppm (1st Batch) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "TESTS[test_num].batch[1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In condition A, we have: \n",
      "Fish group 1 : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch)\\1\\trajectories.txt \n",
      "Fish group 2 : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch)\\2\\trajectories.txt \n",
      "Fish group 3 : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch)\\3\\trajectories.txt \n",
      "Fish group 4 : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch)\\4\\trajectories.txt \n",
      "Fish group 5 : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch)\\5\\trajectories.txt \n",
      "Fish group 6 : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch)\\6\\trajectories.txt \n",
      "Fish group 7 : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch)\\7\\trajectories.txt \n",
      "Fish group 8 : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch)\\8\\trajectories.txt \n",
      "Fish group 9 : D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\01 - Novel Tank Test\\A - Control (1st Batch)\\9\\trajectories.txt \n",
      "\n"
     ]
    }
   ],
   "source": [
    "TESTS[test_num].batch[1].condition['A'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish group 1      : 1/trajectories.txt\n",
      "Fish group 2      : 2/trajectories.txt\n",
      "Fish group 3      : 3/trajectories.txt\n",
      "Fish group 4      : 4/trajectories.txt\n",
      "Fish group 5      : 5/trajectories.txt\n",
      "Fish group 6      : 6/trajectories.txt\n",
      "Fish group 7      : 7/trajectories.txt\n",
      "Fish group 8      : 8/trajectories.txt\n",
      "Fish group 9      : 9/trajectories.txt\n"
     ]
    }
   ],
   "source": [
    "result_dict_dict = []\n",
    "for k, v in TESTS[test_num].batch[1].condition['A'].targets.items():\n",
    "    print(f'Fish group {k:6} : {v.parent.name}/{v.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish1_path = TESTS[test_num].batch[1].condition['A'].targets['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.executor import noveltank_exec\n",
    "\n",
    "whole = noveltank_exec(fish1_path, segment = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whole',\n",
       " {0: ['Total Distance', 2481.413168537418, 'cm'],\n",
       "  1: ['Average Speed', 5.807192063040949, 'cm/s'],\n",
       "  2: ['Freezing Percentage', 4.231219283875498, '%'],\n",
       "  3: ['Swimming Percentage', 84.79756611280132, '%'],\n",
       "  4: ['Average distance to center', 7.6088, 'cm'],\n",
       "  5: ['Time in top', 21.314237573715246, '%'],\n",
       "  6: ['Time in bottom', 78.68576242628475, '%'],\n",
       "  7: ['Time spent in top/bottom ratio', 16.552973130784814, ''],\n",
       "  8: ['Distance traveled in top', 41074.76550517549, 'cm'],\n",
       "  9: ['Distance traveled top/bottom ratio', 16.552973130784814, ''],\n",
       "  10: ['Latency in frames', 2066, 'frames'],\n",
       "  11: ['Latency in seconds', 41.32, 'seconds'],\n",
       "  12: ['Number of entries', 54, ''],\n",
       "  13: ['Average entry', 84.33333333333333, 'seconds']}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For segment 0 - 1 MIN\n",
      "For segment 5 - 6 MIN\n",
      "For segment 10 - 11 MIN\n",
      "For segment 15 - 16 MIN\n",
      "For segment 20 - 21 MIN\n",
      "For segment 25 - 26 MIN\n",
      "For segment 30 - 31 MIN\n"
     ]
    }
   ],
   "source": [
    "seg = {}\n",
    "for segment in range(int(420/60)):\n",
    "    print(f\"For segment {segment*5} - {segment*5+1} MIN\")\n",
    "    seg[segment] = noveltank_exec(fish1_path, segment = segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-6 MIN',\n",
       " {0: ['Total Distance', 321.1376683369885, 'cm'],\n",
       "  1: ['Average Speed', 5.354079165338264, 'cm/s'],\n",
       "  2: ['Freezing Percentage', 5.9686562187395795, '%'],\n",
       "  3: ['Swimming Percentage', 83.36112037345782, '%'],\n",
       "  4: ['Average distance to center', 8.9818, 'cm'],\n",
       "  5: ['Time in top', 19.066666666666666, '%'],\n",
       "  6: ['Time in bottom', 80.93333333333334, '%'],\n",
       "  7: ['Time spent in top/bottom ratio', 19.33189537179979, ''],\n",
       "  8: ['Distance traveled in top', 6208.199804234403, 'cm'],\n",
       "  9: ['Distance traveled top/bottom ratio', 19.33189537179979, ''],\n",
       "  10: ['Latency in frames', 37, 'frames'],\n",
       "  11: ['Latency in seconds', 0.74, 'seconds'],\n",
       "  12: ['Number of entries', 9, ''],\n",
       "  13: ['Average entry', 63.55555555555556, 'seconds']}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5772\n",
      "8.4746\n",
      "9.2793\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "\n",
    "file_path = r'D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\02 - Shoaling Test (Summary).xlsx'\n",
    "output_path = r'D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\merged shoal.xlsx'\n",
    "\n",
    "\n",
    "def merge_cells(file_path, col_name = 'Shoaling Area', cell_step=3, inplace = True):\n",
    "    # Load the Excel workbook\n",
    "    workbook = openpyxl.load_workbook(filename=file_path)\n",
    "\n",
    "    # Get the active worksheet\n",
    "    worksheet = workbook.active\n",
    "\n",
    "    # Find the column index for the \"Shoaling Area\" header\n",
    "    shoaling_area_col = None\n",
    "    for col_idx in range(1, worksheet.max_column+1):\n",
    "        header = worksheet.cell(row=1, column=col_idx).value\n",
    "        if header and col_name in header:\n",
    "            shoaling_area_col = col_idx\n",
    "            break\n",
    "\n",
    "    if shoaling_area_col is None:\n",
    "        print(\"Column not found.\")\n",
    "    else:\n",
    "        # Merge every next 3 rows of the Shoaling Area column\n",
    "        for row_idx in range(2, worksheet.max_row+1, cell_step):\n",
    "            value = worksheet.cell(row=row_idx, column=shoaling_area_col).value\n",
    "            print(value)\n",
    "            if value is not None:\n",
    "                # Merge the current row with the next 2 rows\n",
    "                worksheet.merge_cells(start_row=row_idx, start_column=shoaling_area_col, end_row=row_idx+2, end_column=shoaling_area_col)\n",
    "            \n",
    "            # align the merged cell, horizontal and vertical center\n",
    "            worksheet.cell(row=row_idx, column=shoaling_area_col).alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center')\n",
    "        \n",
    "    # define output_path\n",
    "    if inplace == False:\n",
    "        output_path = file_path[:-5] + '_merged.xlsx'        \n",
    "    else:\n",
    "        output_path = file_path    \n",
    "\n",
    "    # Save the modified workbook\n",
    "    workbook.save(filename=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/1/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/10/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/2/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/3/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/4/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/5/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/6/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/7/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/8/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/9/trajectories.txt')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "full_path = r'D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\03 - Mirror Biting Test\\B - 0.1 ppm (1st Batch)'\n",
    "\n",
    "condition_path = Path(full_path)\n",
    "trajectory_format = \"trajectories.txt\"\n",
    "trajectories = condition_path.glob(f'**/{trajectory_format}')\n",
    "list(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/1/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/2/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/2 - 2/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/2 - 5/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/3/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/4/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/5/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/6/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/7/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/8/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/9/trajectories.txt'),\n",
       " WindowsPath('D:/Code/TowerAssayAnalyzer/Input/OnlyTXT/03 - Mirror Biting Test/B - 0.1 ppm (1st Batch)/10/trajectories.txt')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def sort_paths_by_parent(paths):\n",
    "    def sort_key(path):\n",
    "        name_parts = path.parent.name.split('-')\n",
    "        if len(name_parts) >= 2:\n",
    "            try:\n",
    "                primary_key = int(name_parts[0].strip())\n",
    "            except ValueError:\n",
    "                primary_key = int(name_parts[0].strip())\n",
    "            secondary_key = int(name_parts[1].strip())\n",
    "        else:\n",
    "            primary_key = int(name_parts[0].strip())\n",
    "            secondary_key = 0\n",
    "        return (primary_key, secondary_key)\n",
    "    \n",
    "    return sorted(paths, key=sort_key)\n",
    "\n",
    "full_path = r'D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT\\03 - Mirror Biting Test\\B - 0.1 ppm (1st Batch)'\n",
    "condition_path = Path(full_path)\n",
    "trajectory_format = \"trajectories.txt\"\n",
    "trajectories = condition_path.glob(f'**/{trajectory_format}')\n",
    "\n",
    "sorted_trajectories = sort_paths_by_parent(trajectories)\n",
    "\n",
    "sorted_trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_trajectories = sorted(list(trajectories), key=lambda p: p.parent)\n",
    "sorted_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01 - Novel Tank Test', '02 - Shoaling Test', '03 - Mirror Biting Test', '04 - Social Interaction Test', '05 - Predator Test', '01 - Novel Tank Test\\\\A - Control (1st Batch)', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)', '01 - Novel Tank Test\\\\A - Control (1st Batch)\\\\1', '01 - Novel Tank Test\\\\A - Control (1st Batch)\\\\2', '01 - Novel Tank Test\\\\A - Control (1st Batch)\\\\3', '01 - Novel Tank Test\\\\A - Control (1st Batch)\\\\4', '01 - Novel Tank Test\\\\A - Control (1st Batch)\\\\5', '01 - Novel Tank Test\\\\A - Control (1st Batch)\\\\6', '01 - Novel Tank Test\\\\A - Control (1st Batch)\\\\7', '01 - Novel Tank Test\\\\A - Control (1st Batch)\\\\8', '01 - Novel Tank Test\\\\A - Control (1st Batch)\\\\9', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\1', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\10', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\2', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\3', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\4', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\5', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\6', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\7', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\8', '01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)\\\\9', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)\\\\1', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)\\\\10', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)\\\\2', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)\\\\4', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)\\\\5', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)\\\\6', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)\\\\7', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)\\\\8', '01 - Novel Tank Test\\\\C - 10 ppm (1st Batch)\\\\9', '02 - Shoaling Test\\\\A - Control (1st Batch)', '02 - Shoaling Test\\\\B - 0.1 ppm (1st Batch)', '02 - Shoaling Test\\\\C - 10 ppm (1st Batch)', '02 - Shoaling Test\\\\A - Control (1st Batch)\\\\1', '02 - Shoaling Test\\\\A - Control (1st Batch)\\\\2', '02 - Shoaling Test\\\\A - Control (1st Batch)\\\\2 - 2', '02 - Shoaling Test\\\\A - Control (1st Batch)\\\\3', '02 - Shoaling Test\\\\B - 0.1 ppm (1st Batch)\\\\1', '02 - Shoaling Test\\\\B - 0.1 ppm (1st Batch)\\\\2', '02 - Shoaling Test\\\\B - 0.1 ppm (1st Batch)\\\\3', '02 - Shoaling Test\\\\C - 10 ppm (1st Batch)\\\\1', '02 - Shoaling Test\\\\C - 10 ppm (1st Batch)\\\\2', '02 - Shoaling Test\\\\C - 10 ppm (1st Batch)\\\\3', '03 - Mirror Biting Test\\\\A - Control (1st Batch)', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)', '03 - Mirror Biting Test\\\\A - Control (1st Batch)\\\\1', '03 - Mirror Biting Test\\\\A - Control (1st Batch)\\\\2', '03 - Mirror Biting Test\\\\A - Control (1st Batch)\\\\3', '03 - Mirror Biting Test\\\\A - Control (1st Batch)\\\\4', '03 - Mirror Biting Test\\\\A - Control (1st Batch)\\\\5', '03 - Mirror Biting Test\\\\A - Control (1st Batch)\\\\6', '03 - Mirror Biting Test\\\\A - Control (1st Batch)\\\\7', '03 - Mirror Biting Test\\\\A - Control (1st Batch)\\\\8', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\1', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\10', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\2', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\3', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\4', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\5', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\6', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\7', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\8', '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)\\\\9', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)\\\\1', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)\\\\2', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)\\\\3', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)\\\\4', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)\\\\5', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)\\\\6', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)\\\\7', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)\\\\8', '03 - Mirror Biting Test\\\\C - 10 ppm (1st Batch)\\\\9', '04 - Social Interaction Test\\\\A - Control (1st Batch)', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)', '04 - Social Interaction Test\\\\A - Control (1st Batch)\\\\1', '04 - Social Interaction Test\\\\A - Control (1st Batch)\\\\2', '04 - Social Interaction Test\\\\A - Control (1st Batch)\\\\3', '04 - Social Interaction Test\\\\A - Control (1st Batch)\\\\4', '04 - Social Interaction Test\\\\A - Control (1st Batch)\\\\5', '04 - Social Interaction Test\\\\A - Control (1st Batch)\\\\6', '04 - Social Interaction Test\\\\A - Control (1st Batch)\\\\7', '04 - Social Interaction Test\\\\A - Control (1st Batch)\\\\8', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\1', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\10', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\2', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\3', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\4', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\5', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\6', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\7', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\8', '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)\\\\9', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)\\\\1', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)\\\\2', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)\\\\3', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)\\\\4', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)\\\\5', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)\\\\6', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)\\\\7', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)\\\\8', '04 - Social Interaction Test\\\\C - 10 ppm (1st Batch)\\\\9', '05 - Predator Test\\\\A - Control (1st Batch)', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)', '05 - Predator Test\\\\C - 10 ppm (1st Batch)', '05 - Predator Test\\\\A - Control (1st Batch)\\\\1', '05 - Predator Test\\\\A - Control (1st Batch)\\\\2', '05 - Predator Test\\\\A - Control (1st Batch)\\\\3', '05 - Predator Test\\\\A - Control (1st Batch)\\\\4', '05 - Predator Test\\\\A - Control (1st Batch)\\\\5', '05 - Predator Test\\\\A - Control (1st Batch)\\\\6', '05 - Predator Test\\\\A - Control (1st Batch)\\\\7', '05 - Predator Test\\\\A - Control (1st Batch)\\\\8', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\1', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\10', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\2', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\3', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\4', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\5', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\6', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\7', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\8', '05 - Predator Test\\\\B - 0.1 ppm (1st Batch)\\\\9', '05 - Predator Test\\\\C - 10 ppm (1st Batch)\\\\1', '05 - Predator Test\\\\C - 10 ppm (1st Batch)\\\\2', '05 - Predator Test\\\\C - 10 ppm (1st Batch)\\\\3', '05 - Predator Test\\\\C - 10 ppm (1st Batch)\\\\4', '05 - Predator Test\\\\C - 10 ppm (1st Batch)\\\\5', '05 - Predator Test\\\\C - 10 ppm (1st Batch)\\\\6', '05 - Predator Test\\\\C - 10 ppm (1st Batch)\\\\7', '05 - Predator Test\\\\C - 10 ppm (1st Batch)\\\\8', '05 - Predator Test\\\\C - 10 ppm (1st Batch)\\\\9']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "dir_path = Path(r'D:\\Code\\TowerAssayAnalyzer\\Input\\OnlyTXT')\n",
    "\n",
    "path_list = []\n",
    "\n",
    "for child_dir in dir_path.rglob('*/'):\n",
    "    if child_dir.is_dir():\n",
    "        path_list.append(child_dir.relative_to(dir_path))\n",
    "\n",
    "path_list = [str(path) for path in path_list]\n",
    "\n",
    "print(path_list)\n",
    "\n",
    "# write to .csv file\n",
    "with open('path_list.csv', 'w') as f:\n",
    "    for path in path_list:\n",
    "        f.write(\"%s %s\" % (path, '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from .csv file\n",
    "with open('path_list.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    path_list = list(reader)\n",
    "\n",
    "path_list = [path[0].strip() for path in path_list]\n",
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_path = [dir_path / Path(path) for path in path_list]\n",
    "\n",
    "full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01 - Novel Tank Test',\n",
       " '02 - Shoaling Test',\n",
       " '03 - Mirror Biting Test',\n",
       " '04 - Social Interaction Test',\n",
       " '05 - Predator Test',\n",
       " '01 - Novel Tank Test\\\\A - Control ({} Batch)',\n",
       " '01 - Novel Tank Test\\\\B - {} {} ({} Batch)',\n",
       " '01 - Novel Tank Test\\\\C - {} {} ({} Batch)',\n",
       " '02 - Shoaling Test\\\\A - Control ({} Batch)',\n",
       " '02 - Shoaling Test\\\\B - {} {} ({} Batch)',\n",
       " '02 - Shoaling Test\\\\C - {} {} ({} Batch)',\n",
       " '03 - Mirror Biting Test\\\\A - Control ({} Batch)',\n",
       " '03 - Mirror Biting Test\\\\B - {} {} ({} Batch)',\n",
       " '03 - Mirror Biting Test\\\\C - {} {} ({} Batch)',\n",
       " '04 - Social Interaction Test\\\\A - Control ({} Batch)',\n",
       " '04 - Social Interaction Test\\\\B - {} {} ({} Batch)',\n",
       " '04 - Social Interaction Test\\\\C - {} {} ({} Batch)',\n",
       " '05 - Predator Test\\\\A - Control ({} Batch)',\n",
       " '05 - Predator Test\\\\B - {} {} ({} Batch)',\n",
       " '05 - Predator Test\\\\C - {} {} ({} Batch)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "dir_path = Path(r'D:\\Code\\TowerAssayAnalyzer\\Input\\Test')\n",
    "\n",
    "structure_csv = 'templates/dir_structure.csv'\n",
    "\n",
    "with open(structure_csv, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    path_list = list(reader)\n",
    "\n",
    "path_list = [path[0].strip() for path in path_list]\n",
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01 - Novel Tank Test\\\\B - 0.01 ppm (1st Batch)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list[6].format(0.01, 'ppm', '1st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 - Novel Tank Test\n",
      "02 - Shoaling Test\n",
      "03 - Mirror Biting Test\n",
      "04 - Social Interaction Test\n",
      "05 - Predator Test\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "dir_path = Path(r'D:\\Code\\TowerAssayAnalyzer\\Input\\Test')\n",
    "\n",
    "structure_json = 'templates/dir_structure.json'\n",
    "\n",
    "with open(structure_json, 'r') as f:\n",
    "    path_dict = json.load(f)\n",
    "\n",
    "for path in path_dict['Parent']:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 - Novel Tank Test\\A - Control (1st Batch)\n",
      "02 - Shoaling Test\\A - Control (1st Batch)\n",
      "03 - Mirror Biting Test\\A - Control (1st Batch)\n",
      "04 - Social Interaction Test\\A - Control (1st Batch)\n",
      "05 - Predator Test\\A - Control (1st Batch)\n"
     ]
    }
   ],
   "source": [
    "for path in path_dict['Child-Control']:\n",
    "    print(path.format('1st'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PROJECT():\n",
    "\n",
    "    def __init__(self, name):\n",
    "\n",
    "        self.name = name\n",
    "        if self.name == \"\":\n",
    "            self.status = False\n",
    "        else:\n",
    "            self.status = True\n",
    "\n",
    "    def give_name(self, name):\n",
    "        self.name = name\n",
    "        self.status = True\n",
    "\n",
    "    def info(self):\n",
    "        for key, value in self.__dict__.items():\n",
    "            print(f\"{key} : {value}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = PROJECT(\"\")\n",
    "project.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.give_name(\"test\")\n",
    "project.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Code\\\\TowerAssayAnalyzer\\\\Input\\\\Test'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.dir = r'D:\\Code\\TowerAssayAnalyzer\\Input\\Test'\n",
    "project.dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : test\n",
      "status : True\n",
      "dir : D:\\Code\\TowerAssayAnalyzer\\Input\\Test\n"
     ]
    }
   ],
   "source": [
    "project.get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment_symbols = [chr(i) for i in range(65, 65+26)]\n",
    "treatment_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Parent': ['01 - Novel Tank Test',\n",
       "  '02 - Shoaling Test',\n",
       "  '03 - Mirror Biting Test',\n",
       "  '04 - Social Interaction Test',\n",
       "  '05 - Predator Avoidance Test'],\n",
       " 'Child-A': ['01 - Novel Tank Test\\\\A - Control (1st Batch)',\n",
       "  '02 - Shoaling Test\\\\A - Control (1st Batch)',\n",
       "  '03 - Mirror Biting Test\\\\A - Control (1st Batch)',\n",
       "  '04 - Social Interaction Test\\\\A - Control (1st Batch)',\n",
       "  '05 - Predator Avoidance Test\\\\A - Control (1st Batch)'],\n",
       " 'Child-B': ['01 - Novel Tank Test\\\\B - 0.1 ppm (1st Batch)',\n",
       "  '02 - Shoaling Test\\\\B - 0.1 ppm (1st Batch)',\n",
       "  '03 - Mirror Biting Test\\\\B - 0.1 ppm (1st Batch)',\n",
       "  '04 - Social Interaction Test\\\\B - 0.1 ppm (1st Batch)',\n",
       "  '05 - Predator Avoidance Test\\\\B - 0.1 ppm (1st Batch)'],\n",
       " 'Child-C': ['01 - Novel Tank Test\\\\C - 10.0 ppm (1st Batch)',\n",
       "  '02 - Shoaling Test\\\\C - 10.0 ppm (1st Batch)',\n",
       "  '03 - Mirror Biting Test\\\\C - 10.0 ppm (1st Batch)',\n",
       "  '04 - Social Interaction Test\\\\C - 10.0 ppm (1st Batch)',\n",
       "  '05 - Predator Avoidance Test\\\\C - 10.0 ppm (1st Batch)']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HISTORY_PATH = \"History/projects.json\"\n",
    "ORDINALS = ['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th']\n",
    "CURRENT_PROJECT = \"Melamine\"\n",
    "batch_num = 1\n",
    "TESTLIST = ['Novel Tank Test', \n",
    "                    'Shoaling Test', \n",
    "                    'Mirror Biting Test',\n",
    "                    'Social Interaction Test',\n",
    "                    'Predator Avoidance Test']\n",
    "\n",
    "# turn batch_num into ordinal\n",
    "batch = ORDINALS[int(batch_num)-1]\n",
    "\n",
    "# change number 2 into B, using mathematically\n",
    "\n",
    "with open(HISTORY_PATH, \"r\") as file:\n",
    "    projects_data = json.load(file)\n",
    "\n",
    "treatments = projects_data[CURRENT_PROJECT][\"TREATMENTS\"]\n",
    "\n",
    "all_paths = {}\n",
    "\n",
    "all_paths['Parent'] = []\n",
    "for i, test in enumerate(TESTLIST):\n",
    "    temp = f\"0{i+1} - {test}\"\n",
    "    all_paths['Parent'].append(temp)\n",
    "\n",
    "tail = f\"A - Control ({batch} Batch)\"\n",
    "all_paths['Child-A'] = [f\"{parent}\\\\{tail}\" for parent in all_paths['Parent']]\n",
    "\n",
    "for k, v in treatments.items():\n",
    "    if k == \"Treatment A\":\n",
    "        continue\n",
    "    char = k.split()[1]\n",
    "    tail = f\"{char} - {v[1]} {v[2]} ({batch} Batch)\"\n",
    "    all_paths[f\"Child-{char}\"] = [f\"{parent}\\\\{tail}\" for parent in all_paths['Parent']]\n",
    "\n",
    "all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 - Novel Tank Test\\A - Control (1st Batch)\n",
      "02 - Shoaling Test\\A - Control (1st Batch)\n",
      "03 - Mirror Biting Test\\A - Control (1st Batch)\n",
      "04 - Social Interaction Test\\A - Control (1st Batch)\n",
      "05 - Predator Avoidance Test\\A - Control (1st Batch)\n"
     ]
    }
   ],
   "source": [
    "for v in all_paths['Child-A']:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "HISTORY_PATH = \"History/projects.json\"\n",
    "ORDINALS = ['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th']\n",
    "CURRENT_PROJECT = \"Melamine\"\n",
    "batch_num = 1\n",
    "TESTLIST = ['Novel Tank Test', \n",
    "                    'Shoaling Test', \n",
    "                    'Mirror Biting Test',\n",
    "                    'Social Interaction Test',\n",
    "                    'Predator Avoidance Test']\n",
    "\n",
    "# turn batch_num into ordinal\n",
    "batch = ORDINALS[int(batch_num)-1]\n",
    "\n",
    "# change number 2 into B, using mathematically\n",
    "\n",
    "with open(HISTORY_PATH, \"r\") as file:\n",
    "    projects_data = json.load(file)\n",
    "\n",
    "treatments = projects_data[CURRENT_PROJECT][\"TREATMENTS\"]\n",
    "\n",
    "all_paths = {}\n",
    "\n",
    "all_paths['Parent'] = []\n",
    "for i, test in enumerate(TESTLIST):\n",
    "    temp = f\"0{i+1} - {test}\"\n",
    "    all_paths['Parent'].append(temp)\n",
    "\n",
    "for k, v in treatments.items():\n",
    "    print(v[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['01 - Novel Tank Test',\n",
       "  '03 - Mirror Biting Test',\n",
       "  '04 - Social Interaction Test',\n",
       "  '05 - Predator Avoidance Test'],\n",
       " ['02 - Shoaling Test'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_paths['Parent']\n",
    "\n",
    "normal_parents = []\n",
    "group_parents = []\n",
    "for path in all_paths['Parent']:\n",
    "    if \"Shoaling\" in path:\n",
    "        group_parents.append(path)\n",
    "    else:\n",
    "        normal_parents.append(path)\n",
    "\n",
    "normal_parents, group_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in treatments.items():\n",
    "    char = k.split()[1]\n",
    "    print(char)\n",
    "    if char == \"A\":\n",
    "        tail = f\"A - Control ({batch} Batch)\"\n",
    "    else:\n",
    "        tail = f\"{char} - {v[1]} {v[2]} ({batch} Batch)\"\n",
    "\n",
    "    fish_num = int(v[3])\n",
    "    all_paths[f\"Child-{char}\"] = [f\"{parent}\\\\{tail}\" for parent in all_paths['Parent']]\n",
    "    for i in range(1, fish_num+1):\n",
    "        all_paths[f\"Child-{char}\"].extend([f\"{parent}\\\\{tail}\\\\{i}\" for parent in all_paths['Parent']])\n",
    "\n",
    "all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
